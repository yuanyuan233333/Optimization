{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Barrier (or Interior Point) Method for Linear Programming**\n",
        "\n",
        "\n",
        "Consider the following Linear Programming problem:\n",
        "\\begin{align*}\n",
        "(P)\\quad \\text{min}\\quad          & \\mathbf{c}^T \\mathbf{x} \\\\\n",
        "   \t\\text{ s.t.} \\quad\t& A \\mathbf{x} = \\mathbf{b}\\\\\n",
        "   \t\t              & \\mathbf{x} \\geq \\mathbf{0}.\n",
        "\\end{align*}\n",
        "The constraints that make the problem $(P)$ ``hard'' are the variable nonnegativity constraints. We consider applying the logarithmic barrier method (or interior point method) to the problem where only the constraints $\\mathbf{x} \\geq \\mathbf{0}$ are relaxed.\n",
        "Let $(P(\\mu))$ be the logarithmic barrier problem obtained for a given value of the barrier parameter $\\mu$, that is:\n",
        "\\begin{align*}\n",
        "(P(\\mu))\\quad \t \\text{min}\\quad          &\\mathbf{c}^T \\mathbf{x} - \\mu\\sum_{i=1}^n{\\ln{x_i}} \\\\\n",
        "   \t\t\t\\text{ s.t.}\\quad & A \\mathbf{x} = \\mathbf{b}.\n",
        "\\end{align*}\n"
      ],
      "metadata": {
        "id": "5FoXIAYHfu2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a**) Determine the Karush-Kuhn-Tucker conditions for the original problem $(P)$. Are they necessary and/or sufficient for the optimality in any point of the feasible region?"
      ],
      "metadata": {
        "id": "3u3azGwjj9pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the KKT conditions of the problem $(P)$. If we perturb each complementarity condition by a same parameter $\\mu >0$, we obtain the following perturbed conditions:\n",
        "\\begin{align}\n",
        "\\mathbf{c} - \\mathbf{v} + A^T\\mathbf{u} &= \\mathbf{0} & &(1)\\\\\n",
        "A \\mathbf{x} &= \\vec{b} & &(2)\\\\\n",
        "\\mathbf{x} &\\geq \\mathbf{0} & &(3)\\\\\n",
        "\\mathbf{v} &\\geq \\mathbf{0} & & (4)\\\\\n",
        "x_j v_j &=\\mu & \\text{ for } j = 1, \\dots, n. & (5)\n",
        "\\end{align}\n",
        "**Definition**: Let $\\left ( \\underline{x}\\left ( \\mu\\right ),\\underline{u}\\left ( \\mu\\right ),\\underline{v}\\left ( \\mu\\right )\\right )$ be vectors satisfying the conditions (1)-(5).\n",
        "As $\\mu > 0$ changes, the triplet of vectors $\\left ( \\underline{x}\\left ( \\mu\\right ),\\underline{u}\\left ( \\mu\\right ),\\underline{v}\\left ( \\mu\\right )\\right )$ describe a trajectory called the *central path*.\n",
        "Observe that, when $\\mu$ tends to $0$, the complementary conditions tends to be satisfied.\n",
        "\n",
        "\n",
        "More precisely, we can prove that, if $\\mu \\rightarrow 0$, the triplet $\\left ( \\underline{x}\\left ( \\mu\\right ),\\underline{u}\\left ( \\mu\\right ),\\underline{v}\\left ( \\mu\\right )\\right )$ converges to a triplet $\\left ( \\underline{x}^*,\\underline{u}^*,\\underline{v}^* \\right )$ satisfying the KKT conditions of problem $(P)$.\n",
        "\n",
        "It is possible to verify that\n",
        "\\begin{equation*}\n",
        "L \\left ( \\underline{x}\\left ( \\mu\\right ),\\underline{u}\\left ( \\mu\\right ),\\underline{v}\\left ( \\mu\\right )\\right ) = \\mathbf{c}^T\\mathbf{x}\\left ( \\mu\\right ) - n \\mu \\le \\mathbf{c}^T\\mathbf{x}^* \\le \\mathbf{c}^T\\mathbf{x}\\left ( \\mu\\right )\n",
        "\\end{equation*}\n",
        "where $\\mathbf{x}^*$ is an optimal solution for $(P)$ (for the proof, see Appendix 1). Thus, along the central path, for any $\\mu > 0$ the value of the objective function of $(P)$ $\\mathbf{c}^T\\mathbf{x}\\left ( \\mu\\right )$ is at most $n\\mu$ from the optimal value $\\mathbf{c}^T\\mathbf{x}^*$.    "
      ],
      "metadata": {
        "id": "NZ2KFFkZghq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b**) Consider now the problem with logarithmic barrier $(P(\\mu))$ for a given $\\mu >0$. Determine the Karush-Kuhn-Tucker conditions for such problem. Are they necessary and/or sufficient for optimality in any point of the feasible region?"
      ],
      "metadata": {
        "id": "P2JX2tVikruG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c**) Let $\\mathbf{x}^*\\left ( \\mu \\right )$ be a solution satisfying the KKT conditions of $(P(\\mu))$ for given multipliers $\\mathbf{u}^*\\left ( \\mu \\right )$.\n",
        "   Can the pair $\\left ( \\mathbf{x}^*\\left ( \\mu \\right ), \\mathbf{u}^*\\left ( \\mu \\right )\\right )$ be part of a triplet $\\left ( \\mathbf{x}^*\\left (\\mu \\right ), \\mathbf{u}^*\\left ( \\mu \\right ), \\mathbf{v}^*\\left ( \\mu \\right )\\right )$ belonging to the central path?"
      ],
      "metadata": {
        "id": "nukIB_yjlimS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d**) Consider an iterative algorithm where we apply the Newton method for the solution of the barrier problem at each iteration. Show how one can adapt the rule to derive the Netwon step in order to satisfy a set of linear equality constraints."
      ],
      "metadata": {
        "id": "tbIBCZAoqU96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**e**) Implement the above-method logarithmic barrier method in Matlab and solve the following problem:\n",
        "\\begin{align}\n",
        "\\text{min}\\quad          & x_1 - x_2 & (6)\\\\\n",
        "\\text{ s.t. } & -x_1 + x_2 \\leq 1 & (7)\\\\\n",
        "              & x_1 + x_2  \\leq 3 & (8)\\\\\n",
        "              & x_1, x_2  \\geq 0. & (9)\n",
        "\\end{align}, starting from the feasible solution $\\bar{\\vec{x}}=(1,1)$."
      ],
      "metadata": {
        "id": "Qd8MtE7xo6Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f**) Solve the problem (6)-(9) with the simplex method, using Python and MIP. Verify the solution found with the interior point method is not on a vertex of the feasible polyhedron, as opposed to the one found by MIP. What is the reason?"
      ],
      "metadata": {
        "id": "-Yk33s42qsFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize_scalar\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import ConvexHull\n",
        "from itertools import combinations"
      ],
      "metadata": {
        "id": "79DKVj6BfsGC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extrpts(A, rel, b):\n",
        "    m, n = A.shape\n",
        "    nlv = n\n",
        "\n",
        "    for i in range(m):\n",
        "        e_i = np.zeros(m)\n",
        "        e_i[i] = 1\n",
        "        if rel[i] == '>':\n",
        "            A = np.column_stack([A, -e_i])\n",
        "        else:\n",
        "            A = np.column_stack([A, e_i])\n",
        "\n",
        "        if b[i] < 0:\n",
        "            A[i, :] = -A[i, :]\n",
        "            b[i] = -b[i]\n",
        "\n",
        "    np.seterr(divide='ignore', invalid='ignore')  # Ignore division by zero warnings\n",
        "    vert = []\n",
        "    m, n = A.shape\n",
        "    if n >= m:\n",
        "        t = list(combinations(range(n), m))\n",
        "        nv = len(t)\n",
        "\n",
        "        for i in range(nv):\n",
        "            y = np.zeros(n)\n",
        "            x = np.linalg.lstsq(A[:, list(t[i])], b, rcond=None)[0]\n",
        "            if all(x >= 0) and all(x != np.inf) and all(x != -np.inf):\n",
        "                y[list(t[i])] = x\n",
        "                vert.append(y)\n",
        "    else:\n",
        "        raise ValueError('Number of equations is greater than the number of variables')\n",
        "\n",
        "    vert = np.array(vert).T\n",
        "    #vert = delcols(vert)\n",
        "    vert = np.unique(vert, axis=1)\n",
        "\n",
        "    vert = vert[:nlv, :]\n",
        "    return vert\n",
        "\n",
        "def polyhedron_print(A, b):\n",
        "    m, n = A.shape\n",
        "    Ineq = A[:, :n-m]\n",
        "    rel = '<' * m\n",
        "    t = extrpts(Ineq, rel, b)\n",
        "    t = t[:2, :]\n",
        "    t = np.unique(t, axis=1) #delcols(t)\n",
        "\n",
        "    hull = ConvexHull(t.T)\n",
        "    plt.fill(t[0, hull.vertices], t[1, hull.vertices], color=[0.9, 0.9, 0.5])\n"
      ],
      "metadata": {
        "id": "nPjgTMaz2A9N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interior point method for LPs of the form min c*x:A*x<=b\n",
        "def ipm(c, A, b, mu, x_init, gamma, epsilon):\n",
        "    m, n = A.shape\n",
        "\n",
        "    # Bring to standard form\n",
        "    s = b - A.dot(x_init)\n",
        "    x = np.concatenate([x_init, s])\n",
        "    A = np.concatenate([A, np.eye(m)], axis=1)\n",
        "    c = np.concatenate([c, np.zeros(m)])\n",
        "\n",
        "    grad = np.zeros(m + n)\n",
        "    H = np.zeros((m + n, m + n))\n",
        "    d = np.zeros(m + n)\n",
        "    u = np.zeros(m)\n",
        "\n",
        "    xks = [x_init]\n",
        "\n",
        "    while n * mu >= epsilon:\n",
        "        # compute gradient and Hessian\n",
        "\n",
        "        # compute direction d with adapted Newton update\n",
        "\n",
        "        res = minimize_scalar(lambda alpha: c.dot(x + alpha * d) - mu * np.sum(np.log(x + alpha * d)), bounds=(0, 1), method='bounded')\n",
        "        alpha = res.x\n",
        "\n",
        "        xstar = x + alpha * d\n",
        "        mu = gamma * mu\n",
        "        x = xstar\n",
        "        xks.append(x[:n])\n",
        "\n",
        "\n",
        "    vstar = mu / xstar\n",
        "\n",
        "    polyhedron_print(A, b)\n",
        "    plt.plot(np.array(xks)[:, 0], np.array(xks)[:, 1], 'r.')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"vstar:\", vstar)\n",
        "    print(\"xstar:\", xstar[:n])\n",
        "\n",
        "    return xstar[:n], vstar"
      ],
      "metadata": {
        "id": "Ct-9_MUjp939"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use parameters values $\\mu_0=1$, $\\gamma=0.9$, $\\epsilon=0.001$. Recall that $\\mathbf{c}=(1,-1,0,0)^T$, $\\mathbf{b}=(1,3)^T$ and $\\vec{x}(\\mu_0)=(1,1)^T$.\n",
        "\n",
        "To execute the code we use the command:"
      ],
      "metadata": {
        "id": "Ny6jwJ8Zui0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ipm(np.array([1, -1 ]), np.array([[-1, 1],[1, 1]]), np.array([1, 3]).T, 1, np.array([1, 1]).T, 0.9, 0.00001)"
      ],
      "metadata": {
        "id": "Z_oY4HLS34zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**g**) Solve the problem obtained by replacing the objective function with $\\frac{1}{2} x_1 - x_2$. Verify the solutions of the two methods coincide. Why?"
      ],
      "metadata": {
        "id": "D3KUO0PlrT6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ipm(np.array([1/2, -1 ]), np.array([[-1, 1],[1, 1]]), np.array([1, 3]).T, 1, np.array([1, 1]).T, 0.9, 0.00001)"
      ],
      "metadata": {
        "id": "WIHN_biW7GjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By solving with MIP, we obtain the solution $\\mathbf{x}^s = (1,2,0,0)^T$. The instruction  **x.rc** prints the reduced costs of the variables in the optimal solution found. The presence of null reduced costs indicates that the optimal solution is not unique (it is possible to execute a change of basis, making pivot on a variable with null reduced cost, obtaining a different solution with equal cost). Analytically, this is due to the fact that the gradient of the objective function is orthogonal to the line $-x_1+x_2=1$, corrsponding to the first constraint. Hence, the polyhedron has an optimal facet, the one connecting the points of the segment between $R=(0,1)$ and $S=(1,2)$. All the points in the segment have the same objective function value, but different values of the barrier term. The solution determined by the interior point method, namely *analytical center*, is the solution that, among all those optimal, minimizes the barrier term."
      ],
      "metadata": {
        "id": "w898DPb2vW_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Appendix 1: value of the Lagrangian of $(P)$ along the central path**\n",
        "\n",
        "Let $\\left ( \\tilde{\\mathbf{x}}\\left ( \\mu \\right ), \\tilde{\\mathbf{u}}\\left ( \\mu \\right ), \\tilde{\\mathbf{v}}\\left ( \\mu \\right )\\right )$ be a solution on the central path. The Lagrangian of $(P)$ is:\n",
        "\\begin{align*}\n",
        "L\\left ( \\tilde{\\mathbf{x}}\\left ( \\mu \\right ), \\tilde{\\mathbf{u}}\\left ( \\mu \\right ), \\tilde{\\mathbf{v}}\\left ( \\mu \\right )\\right )= \\mathbf{c}^T\\tilde{\\mathbf{x}}  - \\sum_{j=1}^n\\tilde{v}_j\\tilde{x}_j + \\tilde{\\mathbf{u}}^T(A\\tilde{\\mathbf{x}} - \\mathbf{b}) = \\mathbf{c}^T\\tilde{\\mathbf{x}} - \\sum_{j=1}^n\\tilde{v}_j\\tilde{x}_j = \\mathbf{c}^T\\tilde{\\mathbf{x}} - n \\mu,\n",
        "\\end{align*}\n",
        "since (1)-(5) are satisfied.\n",
        "\n",
        "We can also write:\n",
        "\\begin{align*}\n",
        "L\\left ( \\tilde{\\mathbf{x}}\\left ( \\mu \\right ), \\tilde{\\mathbf{u}}\\left ( \\mu\\right ), \\tilde{\\mathbf{v}}\\left ( \\mu \\right ) \\right )=\n",
        "c^T\\tilde{\\mathbf{x}}  - \\sum_{j=1}^n{\\tilde{v}}_j{\\tilde{x}}_j  =\n",
        "\\left (-A^T\\tilde{\\mathbf{u}}+\\tilde{\\mathbf{v}}\\right )^T\\mathbf{x}  - \\sum_{j=1}^n{\\tilde{v}}_j{\\tilde{x}}_j =\n",
        "\\left (-A^T\\tilde{\\mathbf{u}}\\right )^T{\\tilde{\\mathbf{x}}} = -\\tilde{\\mathbf{u}}^TA\\tilde{\\mathbf{x}} = - \\tilde{\\mathbf{u}}^T\\mathbf{b}\n",
        "\\end{align*}\n",
        "The Lagrangian of $(P)$ evaluated at a solution on the central path coincides with the value of the objective function of the dual problem.\n",
        "\n",
        "\n",
        "[ The dual of $(P)$ is as follows:\n",
        "\\begin{align*}\n",
        " \t\\quad\\text{max }          & \\mathbf{b}^T \\mathbf{u} & (D)\\\\\n",
        "   \t\t\\text{ s.t. } & A^T \\mathbf{u} \\le \\mathbf{c}.\n",
        "\\end{align*}\n",
        "Since the variables $\\mathbf{u}$ are unrestricted in sign, the following problem has the same optimal value of $(D)$:\n",
        "\\begin{align*}\n",
        "\t\t\\quad \\text{max }          & -\\mathbf{b}^T \\mathbf{u} \\\\\n",
        "   \t\t \\text{ s.t. } & -A^T \\mathbf{u} \\le \\mathbf{c}.\n",
        "\\end{align*}]\n",
        "\n",
        "\n",
        "Denoting by $\\mathbf{x}^*$ an optimal solution for $(P)$, it follows that\n",
        "\\begin{align*}\n",
        "c^T\\tilde{\\mathbf{x}} - n \\mu &= - \\tilde{\\mathbf{u}}^T\\mathbf{b} \\le c^T\\mathbf{x}^* &\\text{(due to weak duality in linear programming)}\\\\\n",
        "c^T\\mathbf{x}^* &\\le c^T\\tilde{\\mathbf{x}}  &\\text{(since $c^T\\mathbf{x}^*$ is the optimal value)},\n",
        "\\end{align*}\n",
        "implying that\n",
        "\\begin{align*}\n",
        "c^T\\tilde{\\mathbf{x}} - n \\mu \\le c^T\\mathbf{x}^* \\le c^T\\tilde{\\mathbf{x}}\n",
        "\\end{align*}\n",
        "Then, along the central path, when $\\mu$ tends to $0$, the Lagrangian of $(P)$ tends indeed to the optimal vlaue of the objective function."
      ],
      "metadata": {
        "id": "ELkDZMWDri30"
      }
    }
  ]
}